# Artificial Neural Networks (ANNs) 
![image](https://github.com/YashBajpaiGITHUB/TechBlogzz/assets/146579018/a5426930-52e1-4f48-b7bc-90a2a3596267)

are a computerized model inspired by the intricate workings of biological neural networks found in the human brain.
They are a fundamental concept in the domain of **machine learning** and find wide application in various fields, including **image and speech recognition, natural language processing, autonomous vehicles**, and more. 
Let's look into some key aspects of ANNs:
## 1)Neurons
are the core building blocks , which are also called as **nodes or units**, and are responsible for receiving the input signals and delivering the output signals post processing it.
## 2)Layers: These ANNs are divided into layers. 
![image](https://github.com/YashBajpaiGITHUB/TechBlogzz/assets/146579018/f583d298-100a-46b7-a5f9-b24c2245a5c3)

#### a)Input Layer: 
It receives the input information.
#### b)Hidden Layer:
These are the intermediate layers that are responsible for the computations involved.
#### c)Output Layer:
These are responsible for the final output or predictions.
## 2)Weights and Biases:
Weights are associated with each connection in a neuron such that weightage is adjusted.These represents the strength of the connection. Neurons also have bias which are added to the weighted sum of inputs.

## 3)Activation function: 
![image](https://github.com/YashBajpaiGITHUB/TechBlogzz/assets/146579018/2d01914b-8a55-4408-819d-4834e1150d90)

The hidden layer is introduced with the activation function.They allow the output to differ on the basis of complexity or non-linearity,etc.
## 4)Backpropagation:
In the training phase, information is propelled forward through the network, which is often referred to as the forward movement.
Subsequently, the network's output is examined against the desired target values. Errors are computed, and an optimization algorithm, frequently the well-known backpropagation, comes into play to tweak the weights and biases in order to diminish these errors.
This sequence of actions is recurrently executed until the network reaches a satisfactory solution.
![image](https://github.com/YashBajpaiGITHUB/TechBlogzz/assets/146579018/d9f6d396-18c0-489c-a9fe-8e578caebf4e)

## 5)Loss Function:
The loss function measures how well the network's output aligns with the desired target values. The goal during training is to minimize this loss function.
## 6)Optimization Algorithms:
Various optimization algorithms, such as gradient descent and its variations (like Adam, RMSprop), are employed to update the network's parameters (weights and biases) during training.
## 7)Deep Learning: 
ANNs with multiple hidden layers are often referred to as 'deep neural networks'.
![image](https://github.com/YashBajpaiGITHUB/TechBlogzz/assets/146579018/2d690c9b-1c66-423c-8ff9-34fb8613e749)

## 8)Types of Neural Networks:
There are various types of ANNs, including:

  + **Feedforward Neural Networks (FNNs)**: The simplest type of ANN in which data flows in one direction, from input to output.
  + **Convolutional Neural Networks (CNNs)**: Specialized for image and spatial data, with convolutional layers for feature extraction.
  + **Recurrent Neural Networks (RNNs)**: Designed for sequential data and capable of capturing temporal dependencies.
  + **Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU)**: Special RNN architectures suitable for handling long-range dependencies.
  + **Autoencoders**: Used for data compression and feature learning.
  + **Generative Adversarial Networks (GANs)**: Comprising a generator and discriminator, used for generative tasks.
  + **Transformer Networks**: Used in natural language processing and designed for parallelization.
### Images from internet is taken for reference. 
